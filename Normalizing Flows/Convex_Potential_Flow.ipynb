{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew66iEyY22dB"
   },
   "source": [
    "# <center>Convex Potential FLow [1]</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ux3a7C9kE3WA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "from NF_base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k2D-m3olFAGS"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9Wwv4nF85ulD"
   },
   "outputs": [],
   "source": [
    "class shifting(nn.Module):\n",
    "    def __init__(self, d_in, nh, d_out, n_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(d_in,nh))\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(nh,nh))\n",
    "        self.layers.append(nn.Linear(nh,d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.leaky_relu(layer(x),0.2)\n",
    "        return x\n",
    "\n",
    "class scaling(nn.Module):\n",
    "    def __init__(self, d_in, nh, d_out, n_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(d_in,nh))\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(nh,nh))\n",
    "        self.layers.append(nn.Linear(nh,d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.tanh(layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve3t8Cqj8h9U"
   },
   "source": [
    "**ICNN**: (Input Convex Neural Net)\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        z_1 = L_1(x) \\\\\n",
    "        z_{k+1} = L_{k+1}^+(s(z_k))+L_{k+1}(x) \\\\\n",
    "        F(x) = L_{K+1}^+(s(z_K))+L_{K+1}(x)\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "where $s$ is a convex activation function (e.g. softplus), $L^+$ is a linear layer with positive weights (thus strictly increasing in each argument) and $L$ linear layer.\n",
    "\n",
    "F is convex as a sum of convex function, and composition from a convex function increasing in each argument with a convex function.\n",
    "\n",
    "**Convex Potential Flow:**\n",
    "\\begin{equation*}\n",
    "    f_\\alpha(x) = \\nabla F_\\alpha(x)\n",
    "\\end{equation*}\n",
    "where $F_\\alpha(x)=F(x)+\\frac{\\alpha}{2}\\|x\\|^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICNN(nn.Module):\n",
    "    def __init__(self, d_in, nh, d_out, n_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.params = nn.ParameterList()\n",
    "        self.layers.append(nn.Linear(d_in,nh))\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(d_in,nh))\n",
    "            self.params.append(nn.Parameter(torch.randn(nh,nh)))\n",
    "        self.layers.append(nn.Linear(d_in,d_out))\n",
    "        self.params.append(nn.Parameter(torch.randn(nh,d_out)))\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i,layer in enumerate(self.layers):\n",
    "            if i==0:\n",
    "                z = layer(x)\n",
    "            else:\n",
    "                z = self.softplus(z)@torch.exp(self.params[i-1])+layer(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-10,10,0.1).reshape(-1,1)\n",
    "\n",
    "model = ICNN(1,5,1,3)\n",
    "\n",
    "output = model(x)\n",
    "\n",
    "plt.plot(x.numpy(),output.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100,2)\n",
    "\n",
    "model = ICNN(2,5,2,3)\n",
    "\n",
    "output = model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_alpha(x,alpha=1):\n",
    "    return model(x)+torch.norm(x)*alpha/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2, 100, 2])\n"
     ]
    }
   ],
   "source": [
    "J = torch.autograd.functional.jacobian(F_alpha, x, create_graph=False, strict=False)\n",
    "print(J.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Tensor returned by the function given to hessian should contain a single element",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-13c03edf01eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    427\u001b[0m                                           \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjac_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_single_output_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jacobian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    427\u001b[0m                                           \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Tensor returned by the function given to hessian should contain a single element\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Tensor returned by the function given to hessian should contain a single element"
     ]
    }
   ],
   "source": [
    "H = torch.autograd.functional.hessian(F_alpha, x, create_graph=False, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse():\n",
    "    ## cvxsolver (l-BFGS)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_det():\n",
    "    ## use polynomial tchebyshev algo\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_bPwd_E3DJo"
   },
   "source": [
    "## Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UB7S9dVm4tLF"
   },
   "outputs": [],
   "source": [
    "def train_moons(model, n_epochs=10001):\n",
    "    d = 2\n",
    "    base_distr = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(d,device=device),torch.eye(d,device=device))\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        x, y = datasets.make_moons(128, noise=.1)\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        z, log_det = model(x)\n",
    "        l = loss(z[-1],log_det)\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(i,train_loss[-1])\n",
    "\n",
    "        if (i + 1) % 500 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            xline = torch.linspace(-1.5, 2.5)\n",
    "            yline = torch.linspace(-.75, 1.25)\n",
    "            xgrid, ygrid = torch.meshgrid(xline, yline)\n",
    "            xyinput = torch.cat([xgrid.reshape(-1, 1), ygrid.reshape(-1, 1)], dim=1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                xy, log_s = model(xyinput.to(device))\n",
    "                zz = (log_likelihood(xy[-1],log_s)).exp().cpu()\n",
    "                zgrid = zz.reshape(100,100)\n",
    "\n",
    "\n",
    "                z = base_distr.sample((100,))\n",
    "                xs, _ = model.backward(z)\n",
    "                x = xs[-1].detach()\n",
    "                x = x.cpu().numpy()\n",
    "                z = z.cpu().numpy()\n",
    "\n",
    "            plt.contourf(xgrid.numpy(), ygrid.numpy(), zgrid.numpy())\n",
    "            plt.colorbar()\n",
    "            plt.scatter(x[:,0],x[:,1],c=\"red\")\n",
    "            plt.scatter(z[:,0],z[:,1],c=\"green\")\n",
    "            plt.xlim(-1.5,2.5)\n",
    "            plt.ylim(-0.75,1.25)\n",
    "            plt.title('iteration {}'.format(i + 1))\n",
    "            plt.show()\n",
    "            \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SR-kNpO3G79"
   },
   "outputs": [],
   "source": [
    "def loss(h,log_det,d=2):\n",
    "    base_distr = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(d,device=device),torch.eye(d,device=device))\n",
    "\n",
    "    prior = base_distr.log_prob(h).mean()\n",
    "    return -(prior+log_det.mean())\n",
    "\n",
    "def log_likelihood(h,log_det,d=2):\n",
    "    base_distr = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(d,device=device),torch.eye(d,device=device))\n",
    "\n",
    "    prior = base_distr.log_prob(h)\n",
    "    return prior+log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_kPZ1ao3G_1",
    "outputId": "d7bdef04-d54b-438e-f08a-552029f6b378"
   },
   "outputs": [],
   "source": [
    "d = 2\n",
    "\n",
    "shiftings = [shifting(d//2,64,d//2,3) for k in range(5)]\n",
    "scalings = [shifting(d//2,64,d//2,3) for k in range(5)]\n",
    "\n",
    "flows = []\n",
    "for i in range(5):\n",
    "    flows.append(AffineCoupling(scalings[i],shiftings[i],d))\n",
    "    flows.append(Reverse(d))\n",
    "\n",
    "model = NormalizingFlows(flows).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vv-GjE1b3HDh",
    "outputId": "ee0e7058-3579-428f-bd72-47748da26b11"
   },
   "outputs": [],
   "source": [
    "train_loss = train_moons(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "YIB-e04C8rfa",
    "outputId": "eb0c32b3-8ef9-4e47-b50d-cf9aa1d99b24"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PQA-rKwEzXc",
    "outputId": "9753e2fc-51a8-4b1d-d949-bb24c69dc8cf"
   },
   "outputs": [],
   "source": [
    "d = 2\n",
    "\n",
    "shiftings = [shifting(d//2,64,d//2,3) for k in range(5)]\n",
    "scalings = [shifting(d//2,64,d//2,3) for k in range(5)]\n",
    "\n",
    "flows = []\n",
    "for i in range(5):\n",
    "    flows.append(AffineCoupling(scalings[i],shiftings[i],d))\n",
    "    flows.append(Reverse(d))\n",
    "    flows.append(BatchNorm(d))\n",
    "\n",
    "model = NormalizingFlows(flows).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4njthpunFcsj",
    "outputId": "4cd57403-b238-4191-a14b-5ad1c0fdaf96"
   },
   "outputs": [],
   "source": [
    "train_loss = train_moons(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ng8ocPu3HZm"
   },
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru7PmEX5FiMB"
   },
   "outputs": [],
   "source": [
    "def uniform_quantization(img):\n",
    "    return (img*255+torch.rand(img.size()))/256\n",
    "\n",
    "def rescale_logit(img,lambd=1e-6):\n",
    "    ## logit space\n",
    "    return torch.logit(lambd+(1-2*lambd)*img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gclID9jCFBSd"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                uniform_quantization,\n",
    "                rescale_logit\n",
    "                # torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "n1wFi0KqFCKh",
    "outputId": "4885d0cf-6a89-4ce4-fb4d-c79439cda5e2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_dataset[0][0].reshape(28,28),\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckCArdhzXj1J"
   },
   "outputs": [],
   "source": [
    "def loss(h,log_det,d=784):\n",
    "    base_distr = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(d,device=device),torch.eye(d,device=device))\n",
    "\n",
    "    prior = base_distr.log_prob(h).mean()\n",
    "    return -(prior+log_det.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0BnEbZqXoPc"
   },
   "outputs": [],
   "source": [
    "def log_likelihood(h,log_det,d=784):\n",
    "    base_distr = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(d,device=device),torch.eye(d,device=device))\n",
    "\n",
    "    prior = base_distr.log_prob(h)\n",
    "    return prior+log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBq9YszaXoXN"
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    d = 28*28\n",
    "    torch.manual_seed(42)\n",
    "    r,c = 5,5\n",
    "    z_random = torch.randn(r,c,d,device=device)\n",
    "    model.eval()\n",
    "    zs,log_det = model.backward(z_random.reshape(-1,28*28))\n",
    "    gen_imgs = zs[-1].view(-1,28,28)\n",
    "\n",
    "    cpt = 0\n",
    "    fig,ax = plt.subplots(r,c)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            ax[i,j].imshow(gen_imgs.detach().cpu()[cpt],\"gray\")\n",
    "            cpt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT37qaFgWIIZ"
   },
   "outputs": [],
   "source": [
    "d = 784\n",
    "\n",
    "## Add batch normalization?\n",
    "shiftings = [shifting(d//2,1024,d//2,1) for k in range(5)]\n",
    "scalings = [scaling(d//2,1024,d//2,1) for k in range(5)]\n",
    "\n",
    "flows = []\n",
    "for i in range(5):\n",
    "    flows.append(AffineCoupling(scalings[i],shiftings[i],d))\n",
    "    flows.append(Reverse(d))\n",
    "    flows.append(BatchNorm(d))\n",
    "    \n",
    "model = NormalizingFlows(flows).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6SxDxCCXYGx",
    "outputId": "a05dcfed-a7db-490d-c6c4-04b78133b4c0"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XIYGKuTJXYLS",
    "outputId": "f8748870-a690-43b6-eaf5-3f87323c631f"
   },
   "outputs": [],
   "source": [
    "num_epochs = 101\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_batch = []\n",
    "\n",
    "    for n_batch, (data,_) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        data = data.view(-1,28*28)\n",
    "        z, log_det = model(data)\n",
    "\n",
    "        l = loss(z[-1], log_det)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_batch.append(l.item())\n",
    "\n",
    "\n",
    "    print(epoch, np.mean(train_batch))\n",
    "    train_losses.append(np.mean(train_batch))\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m77aze1WxuAb"
   },
   "outputs": [],
   "source": [
    "test_batch = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for n_batch, (data,_) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    data = data.view(-1,28*28)\n",
    "    z, log_det = model(data)\n",
    "\n",
    "    l = log_likelihood(z[-1], log_det)\n",
    "\n",
    "    test_batch.append(l.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy0-NwgOXYO8",
    "outputId": "37abf752-865f-493c-acdd-55e623e6ca19"
   },
   "outputs": [],
   "source": [
    "# Compute the bits per dim (but irrelevant for binary data)\n",
    "log_likelihood = np.mean(test_batch)\n",
    "bpd = log_likelihood / (np.prod(784) * np.log(2.))\n",
    "print(bpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "I3kya5qPXYS3",
    "outputId": "fdf7389d-7af0-4d39-9e65-c582bf7c9985"
   },
   "outputs": [],
   "source": [
    "d = 28*28\n",
    "torch.manual_seed(42)\n",
    "r,c = 5,5\n",
    "z_random = torch.randn(r,c,d,device=device)\n",
    "model.eval()\n",
    "zs,log_det = model.backward(z_random.reshape(-1,28*28))\n",
    "gen_imgs = zs[-1].view(-1,28,28)\n",
    "gen_imgs = gen_imgs.detach().cpu()\n",
    "lambd = 1e-6\n",
    "gen_imgs = (torch.sigmoid(gen_imgs)-lambd)/(1-2*lambd)\n",
    "\n",
    "cpt = 0\n",
    "fig,ax = plt.subplots(r,c)\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        ax[i,j].imshow(gen_imgs[cpt],\"gray\")\n",
    "        cpt += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HubkxpVT920n"
   },
   "source": [
    "## References\n",
    "\n",
    "<a id=\"reference1\"></a>\n",
    "\n",
    "[1] Dinh, L., Sohl-Dickstein, J., & Bengio, S. Density estimation using Real NVP. arXiv preprint arXiv:1605.08803. (2016). [link](https://arxiv.org/abs/1605.08803)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6_bPwd_E3DJo"
   ],
   "name": "RealNVP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
